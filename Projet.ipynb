{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymanezzouhairi/dataminingProjet/blob/main/Projet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwFnJsE6vjf8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gJr_9dXGpJ05"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# Charger les données\n",
        "data = pd.read_csv('Test.csv')  # Remplacez par votre chemin\n",
        "print(\"Aperçu des données :\\n\", data.head())\n",
        "\n",
        "# Identifier les colonnes numériques et catégoriques\n",
        "numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# 1. Gestion des valeurs manquantes\n",
        "# Remplacer les valeurs manquantes dans les colonnes numériques par la moyenne\n",
        "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())\n",
        "\n",
        "# Remplacer les valeurs manquantes dans les colonnes catégoriques par le mode\n",
        "for col in categorical_columns:\n",
        "    data[col] = data[col].fillna(data[col].mode()[0])\n",
        "\n",
        "# 2. Encodage des variables catégoriques\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    data[col] = label_encoders[col].fit_transform(data[col].astype(str))\n",
        "\n",
        "# Séparation des caractéristiques et de la cible\n",
        "X = data.drop(columns=['ID', 'Segmentation'])\n",
        "y = LabelEncoder().fit_transform(data['Segmentation'])\n",
        "\n",
        "# 3. Normalisation des données avec Min-Max Scaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 4. Sélection des caractéristiques avec Chi-square test\n",
        "chi2_selector = SelectKBest(chi2, k=8)  # Sélectionne les 8 meilleures caractéristiques\n",
        "X_selected = chi2_selector.fit_transform(X_scaled, y)\n",
        "\n",
        "# 5. Division des données pour la classification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Implémentation de l'algorithme Firefly\n",
        "class FireflyAlgorithm:\n",
        "    def __init__(self, obj_function, n_dim, lb, ub, n_fireflies=20, max_iter=50, gamma=1.0, beta0=1.0, alpha=0.5):\n",
        "        self.obj_function = obj_function\n",
        "        self.n_dim = n_dim\n",
        "        self.lb = np.array(lb)\n",
        "        self.ub = np.array(ub)\n",
        "        self.n_fireflies = n_fireflies\n",
        "        self.max_iter = max_iter\n",
        "        self.gamma = gamma\n",
        "        self.beta0 = beta0\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def optimize(self):\n",
        "        fireflies = np.random.uniform(self.lb, self.ub, (self.n_fireflies, self.n_dim))\n",
        "        fitness = np.apply_along_axis(self.obj_function, 1, fireflies)\n",
        "\n",
        "        for t in range(self.max_iter):\n",
        "            for i in range(self.n_fireflies):\n",
        "                for j in range(self.n_fireflies):\n",
        "                    if fitness[i] > fitness[j]:\n",
        "                        distance = cdist([fireflies[i]], [fireflies[j]])[0][0]\n",
        "                        beta = self.beta0 * np.exp(-self.gamma * distance ** 2)\n",
        "                        fireflies[i] += beta * (fireflies[j] - fireflies[i]) + self.alpha * np.random.uniform(-1, 1, self.n_dim)\n",
        "                        fireflies[i] = np.clip(fireflies[i], self.lb, self.ub)\n",
        "                        fitness[i] = self.obj_function(fireflies[i])\n",
        "        best_idx = np.argmin(fitness)\n",
        "        return fireflies[best_idx], fitness[best_idx]\n",
        "\n",
        "# Fonction objectif\n",
        "\n",
        "def svm_objective(params):\n",
        "    C, gamma = params\n",
        "    model = SVC(C=C, kernel='rbf', gamma=gamma)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=make_scorer(accuracy_score))\n",
        "    return -np.mean(scores)  # Négatif car on minimise\n",
        "\n",
        "# Configuration et exécution de Firefly\n",
        "lb = [0.1, 0.001]  # Limites inférieures pour C et gamma\n",
        "ub = [10, 1]       # Limites supérieures pour C et gamma\n",
        "\n",
        "firefly = FireflyAlgorithm(svm_objective, n_dim=2, lb=lb, ub=ub, max_iter=30)\n",
        "best_params, best_score = firefly.optimize()\n",
        "\n",
        "print(f\"Meilleurs paramètres SVM trouvés : C={best_params[0]:.4f}, gamma={best_params[1]:.4f}\")\n",
        "print(f\"Score de validation croisee correspondant : {best_score:.4f}\")\n",
        "\n",
        "# Modèle SVM optimisé\n",
        "svm_model = SVC(C=best_params[0], kernel='rbf', gamma=best_params[1])\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Évaluation\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Modèle Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "print(\"Rapport de classification pour Naive Bayes :\\n\", classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# Modèle Complement Naive Bayes\n",
        "cnb_model = ComplementNB()\n",
        "cnb_model.fit(X_train, y_train)\n",
        "y_pred_cnb = cnb_model.predict(X_test)\n",
        "print(\"Rapport de classification pour Complement Naive Bayes :\\n\", classification_report(y_test, y_pred_cnb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMCECW9Gow_u",
        "outputId": "da1abec7-3a3c-470b-b9c2-ae18120a72d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aperçu des données :\n",
            "        ID  Gender Ever_Married  Age Graduated  Profession  Work_Experience  \\\n",
            "0  458989  Female          Yes   36       Yes    Engineer              0.0   \n",
            "1  458994    Male          Yes   37       Yes  Healthcare              8.0   \n",
            "2  458996  Female          Yes   69        No         NaN              0.0   \n",
            "3  459000    Male          Yes   59        No   Executive             11.0   \n",
            "4  459001  Female           No   19        No   Marketing              NaN   \n",
            "\n",
            "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
            "0            Low          1.0  Cat_6            B  \n",
            "1        Average          4.0  Cat_6            A  \n",
            "2            Low          1.0  Cat_6            A  \n",
            "3           High          2.0  Cat_6            B  \n",
            "4            Low          4.0  Cat_6            A  \n",
            "Meilleurs paramètres SVM trouvés : C=8.3788, gamma=0.1002\n",
            "Score de validation croisee correspondant : -0.3579\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.79      0.48       177\n",
            "           1       0.00      0.00      0.00        97\n",
            "           2       0.00      0.00      0.00       116\n",
            "           3       0.37      0.33      0.35       136\n",
            "\n",
            "    accuracy                           0.35       526\n",
            "   macro avg       0.18      0.28      0.21       526\n",
            "weighted avg       0.21      0.35      0.25       526\n",
            "\n",
            "Rapport de classification pour Naive Bayes :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.72      0.46       177\n",
            "           1       0.00      0.00      0.00        97\n",
            "           2       0.00      0.00      0.00       116\n",
            "           3       0.35      0.38      0.36       136\n",
            "\n",
            "    accuracy                           0.34       526\n",
            "   macro avg       0.17      0.27      0.21       526\n",
            "weighted avg       0.20      0.34      0.25       526\n",
            "\n",
            "Rapport de classification pour Complement Naive Bayes :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.03      0.06       177\n",
            "           1       0.20      0.13      0.16        97\n",
            "           2       0.34      0.61      0.44       116\n",
            "           3       0.34      0.59      0.43       136\n",
            "\n",
            "    accuracy                           0.32       526\n",
            "   macro avg       0.30      0.34      0.27       526\n",
            "weighted avg       0.31      0.32      0.26       526\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}